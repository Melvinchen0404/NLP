{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text_vectorization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPd9dduPVZISS3sgNTFBzeB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/Melvinchen0404/2afad4796dfcca3125d7c2c851a5a238/text_vectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NLP Technique 5: Text Vectorization\n",
        "**Text vectorization** refers to the process of converting text into **numerical representation** \\\n",
        "\\\n",
        "2 METHODS for **text vectorization** are: \\\n",
        "**METHOD 1:** The **bag-of-words (BoW)** model; \\\n",
        "**METHOD 2:** **TF-IDF** or **Term Frequency-Inverse Document Frequency** \\\n",
        "\n",
        "**Word embedding** is the representation of words for text analysis, typically in the form of **real-valued vectors** that encode the meaning of the words such that the **words that are closer in the vector space are expected to be similar in meaning** \\\n",
        "$\\therefore$ Both **METHOD 1** and **METHOD 2** are **word embedding** techniques \\\n",
        "\n",
        "SOURCES: \\\n",
        "https://sites.pitt.edu/~naraehan/presentation/Movie%20Reviews%20sentiment%20analysis%20with%20Scikit-Learn.html \\\n",
        "https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/ \\\n",
        "https://towardsdatascience.com/sentiment-analysis-a-how-to-guide-with-movie-reviews-9ae335e6bcb2"
      ],
      "metadata": {
        "id": "46VE5hJyMBGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**METHOD 1:** The **bag-of-words (BoW)** model \\\n",
        "The **bag-of-words (BoW)** model is the simplest form of text representation in numbers \\\n",
        "Each text (e.g., a sentence or a document) is represented as the **bag (multiset) of its words**\n",
        "\n",
        "**STEP 1 of METHOD 1:** Import `nltk` and `CountVectorizer` \\\n",
        "`CountVectorizer` allows us to convert a collection of text documents to a **matrix of token counts**"
      ],
      "metadata": {
        "id": "D7k77DkwNDwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import CountVectorizer, nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import nltk"
      ],
      "metadata": {
        "id": "BS1FmIPqNdmr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn off pretty printing of jupyter notebook... it generates long lines\n",
        "%pprint"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbnKLBX3ObYD",
        "outputId": "20fb68f1-69d0-4542-c0ae-50c78e112355"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretty printing has been turned OFF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 2 of METHOD 1:** Initialize the `CountVectorizer` \\\n",
        "Its default mode will remove **punctuation** (non-alphabetic characters) and **stopwords** (a set of very common words like 'the', 'a', 'and', etc) \\\n",
        "It will also convert all letters into **lowercase form** \\\n",
        "Its minimum document frequency can be set to 1 with `min_df=1`"
      ],
      "metadata": {
        "id": "mSLXmiNEO1QU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a CountVectorizer to use NLTK's tokenizer instead of its \n",
        "#    default one (which ignores punctuation and stopwords). \n",
        "# Minimum document frequency set to 1. \n",
        "convert = CountVectorizer(min_df=1)"
      ],
      "metadata": {
        "id": "3bm73GdKO9VC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 3 of METHOD 1:** Set the **corpus** \\\n",
        "Here, our **corpus** comprises 3 movie reviews: \\\n",
        "REVIEW 1: This movie is very scary and long. \\\n",
        "REVIEW 2: This movie is not scary and is slow. \\\n",
        "REVIEW 3: This movie is spooky and good. \\\n",
        "\n",
        "**STEP 4 of METHOD 1:** Use the `.fit_transform` method to adapt `convert` to the supplied text data (or `corpus`) and create and return a **count-vectorized output**"
      ],
      "metadata": {
        "id": "_KrhLl-WPmc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = ['This movie is very scary and long.',\n",
        "        'This movie is not scary and is slow.',\n",
        "        'This movie is spooky and good.']"
      ],
      "metadata": {
        "id": "TXfR5k8bQQVj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus_counts = convert.fit_transform(corpus)\n",
        "\n",
        "# fooVzer now contains vocabulary dictionary which maps unique words to index numbers\n",
        "convert.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTxq62KHQal6",
        "outputId": "f5d09248-ed90-4ea7-966a-53b66a75179a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'this': 9, 'movie': 4, 'is': 2, 'very': 10, 'scary': 6, 'and': 0, 'long': 3, 'not': 5, 'slow': 7, 'spooky': 8, 'good': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 5 of METHOD 1:** Use the `.shape` function to determine that we have a dimension of 3 (we have REVIEWS 1-3 in our `corpus`) by 11 (we have 11 **unique words**) \\\n",
        "**STEp 6 of METHOD 1:** Generate the **vector** for each of REVIEWS 1-3 using the `.toarray()` method \\\n",
        "Our vocabulary of **11 unique words** is as follows (in accordance with the index numbering from the previous step): \\\n",
        "'and', 'good', 'is', 'long', 'movie', 'not', 'scary', 'slow', 'spooky', 'this', 'very' \\\n",
        "If a particular **unique word** is present in a review, it will be marked with 1. Otherwise, it will be marked with 0 in the **vector** \\\n",
        "**Vector** of REVIEW 1 (This movie is very scary and long.): [1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1] \\\n",
        "**Vector** of REVIEW 2 (This movie is not scary and is slow.): [1, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0] \\\n",
        "**Vector** of REVIEW 3 (This movie is spooky and good.): [1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0]  "
      ],
      "metadata": {
        "id": "4AylqTaFQ20i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# corpus_counts has a dimension of 3 (there are 3 reviews) by 11 (there are 11 unique words)\n",
        "corpus_counts.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bbOTqlPQtJy",
        "outputId": "eacee45b-18a0-4b87-a88b-8f08faee62de"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this vector is small enough to view in a full, non-sparse form! \n",
        "corpus_counts.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlQ3EzK_RJK8",
        "outputId": "72698788-c6af-4d50-c59f-b5087b259a50"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1],\n",
              "       [1, 0, 2, 0, 1, 1, 1, 1, 0, 1, 0],\n",
              "       [1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**METHOD 2:** **TF-IDF** or **Term Frequency-Inverse Document Frequency** \\\n",
        "**Term Frequent (TF)** is a measure of how frequently a term, $t$, appears in a document, $d$ \\\n",
        "$tf_{t,d} = \\frac{n_{t,d}}{\\text{Number of terms in document $d$}}$ \\\n",
        "\n",
        "Consider REVIEW 2: This movie is not scary and is slow. \\\n",
        "Number of terms in REVIEW 2 = 8 \\\n",
        "'and', 'good', 'is', 'long', 'movie', 'not', 'scary', 'slow', 'spooky', 'this', 'very'\n",
        "\n",
        "TF(and) = $\\frac{1}{8}$ \\\n",
        "TF(good) = $\\frac{0}{8} = 0$ \\\n",
        "TF(is) = $\\frac{2}{8} = \\frac{1}{4}$ \\\n",
        "TF(long) = $\\frac{0}{8} = 0$ \\\n",
        "TF(movie) = $\\frac{1}{8}$ \\\n",
        "TF(not) = $\\frac{1}{8}$ \\\n",
        "TF(scary) = $\\frac{1}{8}$ \\\n",
        "TF(slow) = $\\frac{1}{8}$ \\\n",
        "TF(spooky) = $\\frac{0}{8} = 0$ \\\n",
        "TF(this) = $\\frac{1}{8}$ \\\n",
        "TF(very) = $\\frac{0}{8} = 0$ \\\n",
        "\n",
        "**IDF (Inverse Document Frequency)** is a measure of how important a term is \\\n",
        "$idf_t = \\log{\\frac{\\text{Number of documents}}{\\text{Number of documents with the term $t$}}}$ \\\n",
        "IDF('this') = $\\log{3/3} = 0$ \\\n",
        "IDF('movie') = $\\log{3/3} = 0$ \\\n",
        "IDF('is') = $\\log{3/3} = 0$ \\\n",
        "IDF('not') = $\\log{3/1} = 0.48$ \\\n",
        "IDF('scary') = $\\log{3/2} = 0.18$ \\\n",
        "IDF('and') = $\\log{3/3} = 0$ \\\n",
        "IDF('slow') = $\\log{3/1} = 0.48$ \\\n",
        "\n",
        "NOTE: Terms like 'is', 'this', 'and', etc have little importance and their **IDF** score is reduced to 0, whereas other terms like 'long', 'scary', 'slow', etc are more important and enjoy a higher **IDF** score \\\n",
        "\n",
        "We can compute the **TF-IDF** score from the **TF** and **IDF** scores of each term \\\n",
        "$tfidf_{t,d} = tf_{t,d} \\times idf_t$ \\\n",
        "TF-IDF('this', REVIEW 2) = $\\frac{1}{8} \\times 0 = 0$ \\\n",
        "TF-IDF('movie', REVIEW 2) =  $\\frac{1}{8} \\times 0 = 0$ \\\n",
        "TF-IDF('is', REVIEW 2) = $\\frac{1}{4} \\times 0 = 0$ \\\n",
        "TF-IDF('not', REVIEW 2) = $\\frac{1}{8} \\times 0.48 = 0.06$ \\\n",
        "TF-IDF('scary', REVIEW 2) = $\\frac{1}{8} \\times 0.18 = 0.023$ \\\n",
        "TF-IDF('and', REVIEW 2) = $\\frac{1}{8} \\times 0 = 0$ \\\n",
        "TF-IDF('slow', REVIEW 2) = $\\frac{1}{8} \\times 0.48 = 0.06$ \\\n",
        "\n",
        "NOTE: **TF-IDF** gives higher values for less frequent words \\\n",
        "The **TF-IDF** score is high when both the **IDF** score (i.e.,  the term is **rare in the corpus** or all the documents combined) and the **TF** score (i.e., the term is **frequent in a single document**) \\\n",
        "\n",
        "The **bag-of-words (BoW)** model (**METHOD 1**) merely creates a set of vectors containing the **frequency count of word occurrences** in the corpus \\\n",
        "On the other hand, the **TF-IDF** model (**METHOD 2**) contains information on the more important terms and the less important ones. $\\therefore$ **METHOD 2** typically fares better in **machine learning** approaches"
      ],
      "metadata": {
        "id": "5jrlRt60TcKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 1 of METHOD 2:** Import the `TfidfTransformer` \\\n",
        "This will allow us to **transform** a **count matrix** to a normalized **TF-IDF** representation \\\n",
        "**STEP 2 of METHOD 2:** Use the `fit_transform()` method to convert the raw **frequency counts** of words into **TF-IDF** scores \\\n",
        "NOTE: Under the **standard textbook** method: \\\n",
        "$idf_t = \\log{\\frac{\\text{Number of documents}}{\\text{Number of documents with the term $t$}}}$ \\\n",
        "Under the **Scikit-Learn (Sklearn)** method: \\\n",
        "$idf_t = \\log{\\frac{\\text{Number of documents} \\ + \\ 1}{\\text{Number of documents with the term $t$} \\ + \\ 1} + 1}$ \\\n",
        "The **Scikit-Learn (Sklearn)** method ensures that terms that occur in all documents in the training set or corpus (i.e., terms with a zero **IDF** score under the **standard textbook** approach) will not be completely ignored \\"
      ],
      "metadata": {
        "id": "4hINIzIIYZh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert raw frequency counts into TF-IDF (Term Frequency -- Inverse Document Frequency) values\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "fooTfmer = TfidfTransformer()\n",
        "\n",
        "# Again, fit and transform\n",
        "corpus_tfidf = fooTfmer.fit_transform(corpus_counts)"
      ],
      "metadata": {
        "id": "f9fpJzjBYeQf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF values are returned\n",
        "# Raw counts have been normalized against document length \n",
        "# Terms that are found across many documents are weighted down ('a' vs. 'scary')\n",
        "corpus_tfidf.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCedJ5nLZAtu",
        "outputId": "ae773bf1-dbba-4821-87bc-c2dd5cac7028"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.29628336, 0.        , 0.29628336, 0.50165133, 0.29628336,\n",
              "        0.        , 0.38151877, 0.        , 0.        , 0.29628336,\n",
              "        0.50165133],\n",
              "       [0.26359985, 0.        , 0.5271997 , 0.        , 0.26359985,\n",
              "        0.44631334, 0.3394328 , 0.44631334, 0.        , 0.26359985,\n",
              "        0.        ],\n",
              "       [0.32052772, 0.54270061, 0.32052772, 0.        , 0.32052772,\n",
              "        0.        , 0.        , 0.        , 0.54270061, 0.32052772,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 3 of METHOD 2:** **Transform** new data or reviews into **count-vectorized** form \\\n",
        "\n",
        "Suppose we introduce a new review (REVIEW 4) \\\n",
        "REVIEW 4: This movie is filled with good actors and is very good. \\\n",
        "**STEP 3A of METHOD 2:** Define REVIEW 4 as `newdata` \\\n",
        "**STEP 3B of METHOD 2:** **Transform** new data or reviews into **count-vectorized** form using the `transform()` method. No fitting is needed \\\n",
        "This will yield the **vector** of REVIEW 4 under the **BoW** model \\\n",
        "Unseen words (e.g., 'actors', 'filled', 'with') are ignored"
      ],
      "metadata": {
        "id": "HEd3DXaNZnPB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A list of new documents\n",
        "newdata = [\"This movie is filled with good actors and is very good.\"]"
      ],
      "metadata": {
        "id": "9mDQUMBkZ1hm"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "newdata_counts = convert.transform(newdata)\n",
        "newdata_counts.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byiwtLy2anKP",
        "outputId": "9941d83a-5dbf-45ac-ac65-9fee9b54aedc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2, 2, 0, 1, 0, 0, 0, 0, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**STEP 3C of METHOD 2:** **Transform** new data or reviews using `tfidf` to derive the **TF-IDF** scores of the terms \\"
      ],
      "metadata": {
        "id": "K0E5mJSza7By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Again, transform using tfidf \n",
        "newdata_tfidf = fooTfmer.transform(newdata_counts)\n",
        "newdata_tfidf.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fpimvxua7ir",
        "outputId": "5ac89182-bfa2-4911-8497-eddc7366578e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2165043 , 0.7331473 , 0.43300861, 0.        , 0.2165043 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.2165043 ,\n",
              "        0.36657365]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}